## Set up and customize a basic pipeline for AI model training and inference on AWS.

This project demonstrates how to deploy an AI model on AWS SageMaker using a customized Docker image. It covers the entire workflow, including creating a training job, deploying an inference endpoint, and invoking predictions. The project also explores best practices for managing resources efficiently and separating model execution logic from the container image.

### Detailed post: [Basic pipeline for AI model training and inference on AWS.](https://0001-workshop.cuongnv.social/)
